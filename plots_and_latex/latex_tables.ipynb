{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from DatasetManager import DatasetManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\toprule  &  & min  & med  & max      & \\# distinct & \\# static  & \\# dynamic  & \\# static  & \\# dynamic \\\\ \n",
      " dataset & \\# traces &  length &  length & length &   activities &    attr-s &   attr-s &  cat levels & cat levels\\\\ \\midrule\n",
      "bpic2011\\_1 & 1140 & 1 & 25.0  & 1814 & 193 & 6 & 14 & 961 & 290 \\\\\n",
      "bpic2011\\_2 & 1140 & 1 & 54.5  & 1814 & 251 & 6 & 14 & 994 & 370 \\\\\n",
      "bpic2011\\_3 & 1121 & 1 & 21.0  & 1368 & 190 & 6 & 14 & 886 & 283 \\\\\n",
      "bpic2011\\_4 & 1140 & 1 & 44.0  & 1432 & 231 & 6 & 14 & 993 & 338 \\\\\n",
      "bpic2015\\_1 & 694 & 2 & 42.5  & 101 & 380 & 17 & 12 & 17 & 432 \\\\\n",
      "bpic2015\\_2 & 753 & 1 & 55.0  & 132 & 396 & 17 & 12 & 7 & 429 \\\\\n",
      "bpic2015\\_3 & 1325 & 3 & 42.0  & 124 & 380 & 18 & 12 & 17 & 428 \\\\\n",
      "bpic2015\\_4 & 577 & 1 & 42.0  & 82 & 319 & 15 & 12 & 9 & 347 \\\\\n",
      "bpic2015\\_5 & 1051 & 5 & 50.0  & 134 & 376 & 18 & 12 & 8 & 419 \\\\\n",
      "production & 220 & 1 & 9.0  & 78 & 26 & 3 & 15 & 37 & 79 \\\\\n",
      "sepsis\\_1 & 754 & 5 & 14.0  & 185 & 14 & 24 & 13 & 195 & 38 \\\\\n",
      "sepsis\\_2 & 782 & 4 & 13.0  & 60 & 15 & 24 & 13 & 200 & 40 \\\\\n",
      "sepsis\\_3 & 782 & 4 & 13.0  & 185 & 15 & 24 & 13 & 200 & 40 \\\\\n",
      "bpic2012\\_1 & 4685 & 15 & 35.0  & 175 & 36 & 1 & 10 & 0 & 98 \\\\\n",
      "bpic2012\\_2 & 4685 & 15 & 35.0  & 175 & 36 & 1 & 10 & 0 & 99 \\\\\n",
      "bpic2012\\_3 & 4685 & 15 & 35.0  & 175 & 36 & 1 & 10 & 0 & 98 \\\\\n",
      "bpic2017\\_1 & 31413 & 10 & 35.0  & 180 & 26 & 3 & 20 & 13 & 194 \\\\\n",
      "bpic2017\\_2 & 31413 & 10 & 35.0  & 180 & 26 & 3 & 20 & 13 & 194 \\\\\n",
      "bpic2017\\_3 & 31413 & 10 & 35.0  & 180 & 26 & 3 & 20 & 13 & 194 \\\\\n",
      "traffic & 129597 & 2 & 4.0  & 20 & 10 & 4 & 14 & 53 & 172 \\\\\n",
      "\\bottomrule\n"
     ]
    }
   ],
   "source": [
    "dt_stats = []\n",
    "datasets = [\"bpic2011_f%s\"%formula for formula in range(1,5)] + [\"bpic2015_%s_f2\"%(municipality) for municipality in range(1,6)] + [\"production\",\n",
    "                                                                                                                                    \"sepsis_cases_1\", \"sepsis_cases_2\", \"sepsis_cases_4\",\n",
    "                                                                                                                                    \"bpic2012_accepted\", \"bpic2012_declined\", \"bpic2012_cancelled\",\n",
    "                                                                                                                                    \"bpic2017_accepted\", \"bpic2017_refused\", \"bpic2017_cancelled\",\n",
    "                                                                                                                                    \"traffic_fines_1\",]\n",
    "#datasets = [\"unemployment\"]\n",
    "print(\"\\\\toprule  &  & min  & med  & max      & \\\\# distinct & \\\\# static  & \\\\# event  & \\\\# case  & \\\\# dynamic \\\\\\\\ \")\n",
    "print(\" dataset & \\\\# cases &  length &  length & length &   activities &    variables &   variables &  cat levels & cat levels\\\\\\\\ \\\\midrule\")\n",
    "for dataset_name in datasets:\n",
    "    dataset_manager = DatasetManager(dataset_name)\n",
    "    \n",
    "    case_id_col = dataset_confs.case_id_col[dataset_name]\n",
    "    activity_col = dataset_confs.activity_col[dataset_name]\n",
    "    timestamp_col = dataset_confs.timestamp_col[dataset_name]\n",
    "    label_col = dataset_confs.label_col[dataset_name]\n",
    "    pos_label = dataset_confs.pos_label[dataset_name]\n",
    "\n",
    "    dynamic_cat_cols = dataset_confs.dynamic_cat_cols[dataset_name]\n",
    "    static_cat_cols = dataset_confs.static_cat_cols[dataset_name]\n",
    "    dynamic_num_cols = dataset_confs.dynamic_num_cols[dataset_name]\n",
    "    static_num_cols = dataset_confs.static_num_cols[dataset_name]\n",
    "\n",
    "    data_filepath = os.path.join(home_dir, dataset_confs.filename[dataset_name])\n",
    "\n",
    "    # specify data types\n",
    "    dtypes = {col:\"object\" for col in dynamic_cat_cols+static_cat_cols+[case_id_col, label_col, timestamp_col]}\n",
    "    for col in dynamic_num_cols + static_num_cols:\n",
    "        dtypes[col] = \"float\"\n",
    "            \n",
    "    data = pd.read_csv(data_filepath, sep=\";\", dtype=dtypes)\n",
    "    sizes = data.groupby(case_id_col).size()\n",
    "\n",
    "    class_freqs = data.groupby(case_id_col).first()[label_col].value_counts()\n",
    "    \n",
    "    if \"traffic_fines\" in dataset_name:\n",
    "        max_prefix_length = 10\n",
    "    elif \"bpic2017\" in dataset_name:\n",
    "        max_prefix_length = min(20, dataset_manager.get_pos_case_length_quantile(data, 0.90))\n",
    "    else:\n",
    "        max_prefix_length = min(40, dataset_manager.get_pos_case_length_quantile(data, 0.90))\n",
    "    \n",
    "    n_trace_variants = len(data.sort_values(timestamp_col, kind=\"mergesort\").groupby(case_id_col).head(max_prefix_length).groupby(case_id_col)[activity_col].apply(lambda x: \"__\".join(list(x))).unique())\n",
    "    \n",
    "    n_static_cat_levels = 0\n",
    "    n_dynamic_cat_levels = 0\n",
    "    for col in dynamic_cat_cols:\n",
    "        n_dynamic_cat_levels += len(data[col].unique())\n",
    "    for col in static_cat_cols:\n",
    "        n_static_cat_levels += len(data[col].unique())\n",
    "    \n",
    "    dataset_name = dataset_name.replace(\"_\", \"\\\\_\").replace(\"bpic2011\\_f\", \"bpic2011\\_\").replace(\"\\_f2\", \"\").replace(\"activity\", \"1\").replace(\"followup\", \"2\").replace(\"cases\\_\", \"\").replace(\"billing\\_\", \"\").replace(\"accepted\", \"1\").replace(\"declined\", \"2\").replace(\"refused\", \"2\").replace(\"cancelled\", \"3\").replace(\"\\_fines\\_1\", \"\").replace(\"sepsis\\_4\", \"sepsis\\_3\").replace(\"hospital\\_2\", \"hospital\\_1\").replace(\"hospital\\_3\", \"hospital\\_2\")\n",
    "    print(\"%s & %s & %s & %s  & %s & %s & %s & %s & %s & %s \\\\\\\\\"%(dataset_name, len(data[case_id_col].unique()), sizes.min(), sizes.quantile(0.50), sizes.max(), len(data[activity_col].unique()), len(static_cat_cols) + len(static_num_cols), len(dynamic_cat_cols) + len(dynamic_num_cols),\n",
    "                                                                      n_static_cat_levels, n_dynamic_cat_levels))\n",
    "    \n",
    "    record = (dataset_name, len(data[case_id_col].unique()), sizes.min(), sizes.quantile(0.50), sizes.max(), len(data[activity_col].unique()), len(static_cat_cols) + len(static_num_cols), len(dynamic_cat_cols) + len(dynamic_num_cols),\n",
    "                                                                      n_static_cat_levels, n_dynamic_cat_levels)\n",
    "    dt_stats.append(record)\n",
    "    \n",
    "print(\"\\\\bottomrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kamel/utcs/master_courses/4th/thesis/new_repo/predictive-monitoring-thesis\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>cls</th>\n",
       "      <th>nr_events</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>production</td>\n",
       "      <td>prefix_agg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>1</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.603571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>production</td>\n",
       "      <td>prefix_agg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>1</td>\n",
       "      <td>prec</td>\n",
       "      <td>0.393939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>production</td>\n",
       "      <td>prefix_agg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>1</td>\n",
       "      <td>rec</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>production</td>\n",
       "      <td>prefix_agg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>1</td>\n",
       "      <td>fscore</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>production</td>\n",
       "      <td>prefix_agg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>2</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.608466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset      method      cls  nr_events  metric     score\n",
       "0  production  prefix_agg  xgboost          1     auc  0.603571\n",
       "1  production  prefix_agg  xgboost          1    prec  0.393939\n",
       "2  production  prefix_agg  xgboost          1     rec  0.928571\n",
       "3  production  prefix_agg  xgboost          1  fscore  0.553191\n",
       "4  production  prefix_agg  xgboost          2     auc  0.608466"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat=pd.read_csv('./../../results_all/catboost/code/final_data/auc/data_catboost.csv', sep = ';')\n",
    "data_cat.head()\n",
    "\n",
    "data_wavelet=pd.read_csv('./../../results_all/catboost/code/final_data/auc/data_wavelet.csv', sep = ';')\n",
    "data_wavelet.head()\n",
    "\n",
    "data_inter=pd.read_csv('./../../results_all/catboost/code/final_data/auc/Inter_data_catboost.csv', sep = ';')\n",
    "data_inter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bpic2011_1',\n",
       " 'bpic2011_2',\n",
       " 'bpic2011_3',\n",
       " 'bpic2011_4',\n",
       " 'bpic2012_a',\n",
       " 'bpic2012_c',\n",
       " 'bpic2012_d',\n",
       " 'bpic2015_1',\n",
       " 'bpic2015_2',\n",
       " 'bpic2015_3',\n",
       " 'bpic2015_4',\n",
       " 'bpic2015_5',\n",
       " 'bpic2017_a',\n",
       " 'bpic2017_c',\n",
       " 'bpic2017_r',\n",
       " 'production',\n",
       " 'sepsis_1',\n",
       " 'sepsis_2',\n",
       " 'sepsis_3'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('./../../results_all/catboost/code/final_data/auc/data_wavelet_NODUPLICATE.csv', sep = ';')\n",
    "data = data_inter\n",
    "\n",
    "data.dataset = data.dataset.str.replace(\"sepsis_1\", \"sepsis_cases_1\")\n",
    "data.dataset = data.dataset.str.replace(\"sepsis_2\", \"sepsis_cases_2\")\n",
    "data.dataset = data.dataset.str.replace(\"sepsis_3\", \"sepsis_cases_4\")\n",
    "\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_4\", \"bpic2011_f4\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_3\", \"bpic2011_f3\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_2\", \"bpic2011_f2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_1\", \"bpic2011_f1\")\n",
    "\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_1\", \"bpic2015_1_f2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_2\", \"bpic2015_2_f2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_3\", \"bpic2015_3_f2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_4\", \"bpic2015_4_f2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_5\", \"bpic2015_5_f2\")\n",
    "\n",
    "data.dataset = data.dataset.str.replace(\"bpic2012_A\", \"bpic2012_accepted\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2012_C\", \"bpic2012_cancelled\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2012_D\", \"bpic2012_declined\")\n",
    "\n",
    "data.dataset = data.dataset.str.replace(\"bpic2017_R\", \"bpic2017_refused\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2017_A\", \"bpic2017_accepted\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2017_C\", \"bpic2017_cancelled\")\n",
    "\n",
    "\n",
    "data.dataset = data.dataset.str.replace(\"traffic\", \"traffic_fines_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>cls</th>\n",
       "      <th>nr_events</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "      <th>n_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>production</td>\n",
       "      <td>prefix_agg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>1</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.603571</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>production</td>\n",
       "      <td>prefix_agg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>1</td>\n",
       "      <td>prec</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>production</td>\n",
       "      <td>prefix_agg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>1</td>\n",
       "      <td>rec</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>production</td>\n",
       "      <td>prefix_agg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>1</td>\n",
       "      <td>fscore</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>production</td>\n",
       "      <td>single_agg</td>\n",
       "      <td>logit</td>\n",
       "      <td>1</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49091</th>\n",
       "      <td>bpic2015_3_f2</td>\n",
       "      <td>prefix_laststate</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>fscore</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49092</th>\n",
       "      <td>bpic2015_3_f2</td>\n",
       "      <td>state_agg</td>\n",
       "      <td>rf</td>\n",
       "      <td>1</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.659882</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49093</th>\n",
       "      <td>bpic2015_3_f2</td>\n",
       "      <td>state_agg</td>\n",
       "      <td>rf</td>\n",
       "      <td>1</td>\n",
       "      <td>prec</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49094</th>\n",
       "      <td>bpic2015_3_f2</td>\n",
       "      <td>state_agg</td>\n",
       "      <td>rf</td>\n",
       "      <td>1</td>\n",
       "      <td>rec</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49095</th>\n",
       "      <td>bpic2015_3_f2</td>\n",
       "      <td>state_agg</td>\n",
       "      <td>rf</td>\n",
       "      <td>1</td>\n",
       "      <td>fscore</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49096 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dataset            method      cls  nr_events  metric     score  \\\n",
       "0         production        prefix_agg  xgboost          1     auc  0.603571   \n",
       "1         production        prefix_agg  xgboost          1    prec  0.393939   \n",
       "2         production        prefix_agg  xgboost          1     rec  0.928571   \n",
       "3         production        prefix_agg  xgboost          1  fscore  0.553191   \n",
       "4         production        single_agg    logit          1     auc  0.528571   \n",
       "...              ...               ...      ...        ...     ...       ...   \n",
       "49091  bpic2015_3_f2  prefix_laststate      svm          1  fscore  0.000000   \n",
       "49092  bpic2015_3_f2         state_agg       rf          1     auc  0.659882   \n",
       "49093  bpic2015_3_f2         state_agg       rf          1    prec  0.571429   \n",
       "49094  bpic2015_3_f2         state_agg       rf          1     rec  0.059701   \n",
       "49095  bpic2015_3_f2         state_agg       rf          1  fscore  0.108108   \n",
       "\n",
       "       n_cases  \n",
       "0         44.0  \n",
       "1         44.0  \n",
       "2         44.0  \n",
       "3         44.0  \n",
       "4         44.0  \n",
       "...        ...  \n",
       "49091    265.0  \n",
       "49092    265.0  \n",
       "49093    265.0  \n",
       "49094    265.0  \n",
       "49095    265.0  \n",
       "\n",
       "[49096 rows x 7 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   \n",
    "with open(\"n_test_cases.pickle\", \"rb\") as fin:\n",
    "    test_cases_dict = pickle.load(fin)\n",
    "    \n",
    "    \n",
    "df_test_cases = pd.DataFrame(test_cases_dict)\n",
    "df_test_cases = df_test_cases.stack().reset_index()\n",
    "df_test_cases.columns = [\"nr_events\", \"dataset\", \"n_cases\"]\n",
    "df_test_cases\n",
    "data = pd.merge(data, df_test_cases, on=[\"dataset\", \"nr_events\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dataset = data.dataset.str.replace(\"sepsis_cases_1\", \"sepsis_1\")\n",
    "data.dataset = data.dataset.str.replace(\"sepsis_cases_2\", \"sepsis_2\")\n",
    "data.dataset = data.dataset.str.replace(\"sepsis_cases_4\", \"sepsis_3\")\n",
    "\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_f4\", \"bpic2011_4\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_f3\", \"bpic2011_3\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_f2\", \"bpic2011_2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_f1\", \"bpic2011_1\")\n",
    "\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_1_f2\", \"bpic2015_1\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_2_f2\", \"bpic2015_2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_3_f2\", \"bpic2015_3\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_4_f2\", \"bpic2015_4\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_5_f2\", \"bpic2015_5\")\n",
    "\n",
    "data.dataset = data.dataset.str.replace(\"bpic2012_accepted\", \"bpic2012_a\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2012_cancelled\", \"bpic2012_c\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2012_declined\", \"bpic2012_d\")\n",
    "\n",
    "data.dataset = data.dataset.str.replace(\"bpic2017_refused\", \"bpic2017_r\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2017_accepted\", \"bpic2017_a\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2017_cancelled\", \"bpic2017_c\")\n",
    "\n",
    "data.dataset = data.dataset.str.replace(\"hospital_billing_2\", \"hospital_2\")\n",
    "data.dataset = data.dataset.str.replace(\"hospital_billing_3\", \"hospital_3\")\n",
    "\n",
    "data.dataset = data.dataset.str.replace(\"traffic_fines_1\", \"traffic\")\n",
    "#data.method = data.method.str.replace(\"prefix_index_5\", \"prefix_index\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_prec = 2\n",
    "tmp_auc = data[(data.metric==\"auc\")]\n",
    "tmp_auc.fillna(0, inplace=True)\n",
    "all_mean_aucs = tmp_auc.groupby([\"dataset\", \"method\", \"cls\"]).apply(lambda group: np.average(group[\"score\"], \n",
    "                                                                           weights=group[\"n_cases\"])).reset_index()\n",
    "all_mean_aucs.columns = [\"dataset\", \"method\", \"cls\", \"score\"]\n",
    "best_mean_aucs = all_mean_aucs.groupby([\"dataset\"])[\"score\"].max().round(round_prec)\n",
    "\n",
    "\n",
    "bucket_encs = list(set(data.method))\n",
    "methods = [\"%s\" % (bucket_enc) for bucket_enc in bucket_encs]\n",
    "clfs = [\"catboost\",\"rf\", \"xgboost\", \"logit\",\"svm\"]\n",
    "#cls_methods = [\"catboost\",\"rf\", \"xgboost\", \"logit\",\"svm\"]\n",
    "tmp2_auc = tmp_auc.groupby(\"method\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_prec = 2\n",
    "tmp_fsc = data[(data.metric==\"fscore\")]\n",
    "tmp_fsc.fillna(0, inplace=True)\n",
    "all_mean_fsc = tmp_fsc.groupby([\"dataset\", \"method\", \"cls\"]).apply(lambda group: np.average(group[\"score\"], \n",
    "                                                                           weights=group[\"n_cases\"])).reset_index()\n",
    "all_mean_fsc.columns = [\"dataset\", \"method\", \"cls\", \"score\"]\n",
    "best_mean_fsc = all_mean_fsc.groupby([\"dataset\"])[\"score\"].max().round(round_prec)\n",
    "\n",
    "\n",
    "bucket_encs = list(set(data.method))\n",
    "methods = [\"%s\" % (bucket_enc) for bucket_enc in bucket_encs]\n",
    "clfs = [\"catboost\",\"rf\", \"xgboost\", \"logit\",\"svm\"]\n",
    "#cls_methods = [\"catboost\",\"rf\", \"xgboost\", \"logit\",\"svm\"]\n",
    "tmp2_fsc = tmp_fsc.groupby(\"method\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this many times for many tables 0:6 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\toprule\n",
      " & \\multicolumn{5}{c}{svm}\n",
      "\\\\\n",
      " & bpic2015\\_2 & bpic2015\\_4 & bpic2011\\_4 & bpic2017\\_r & bpic2012\\_d & bpic2012\\_a\n",
      "\\\\ \\midrule\n",
      "cluster\\_laststate & $0.56$ ${(0.0)}$ & $0.58$ ${(0.0)}$ & $0.51$ ${(0.0)}$ & $0.55$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.66$ ${(0.32)}$ \\\\\n",
      "cluster\\_agg & $0.67$ ${(0.46)}$ & $0.56$ ${(0.0)}$ & $0.73$ ${(0.07)}$ & $0.5$ ${(0.0)}$ & $0.53$ ${(0.0)}$ & $0.49$ ${(0.0)}$ \\\\\n",
      "single\\_agg & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.51$ ${(0.71)}$ \\\\\n",
      "prefix\\_agg & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.88$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.51$ ${(0.01)}$ & $0.5$ ${(0.3)}$ \\\\\n",
      "prefix\\_laststate & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.84$ ${(0.0)}$ & $0.56$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ \\\\\n",
      "single\\_laststate & $0.5$ ${(0.0)}$ & $0.53$ ${(0.0)}$ & $0.84$ ${(0.44)}$ & $-$  & $0.54$ ${(0.08)}$ & $0.5$ ${(0.0)}$ \\\\\n",
      "prefix\\_index & $0.68$ ${(0.43)}$ & $0.53$ ${(0.0)}$ & $0.88$ ${(0.71)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ \\\\\n",
      "state\\_agg & $0.7$ ${(0.3)}$ & $0.53$ ${(0.0)}$ & $0.82$ ${(0.64)}$ & $0.5$ ${(0.0)}$ & $0.53$ ${(0.1)}$ & $0.6$ ${(0.36)}$ \\\\\n",
      "state\\_laststate & $0.71$ ${(0.3)}$ & $0.53$ ${(0.0)}$ & $0.49$ ${(0.09)}$ & $-$  & $0.52$ ${(0.09)}$ & $0.66$ ${(0.39)}$ \\\\\n",
      "\\bottomrule\n",
      "\\toprule\n",
      " & \\multicolumn{5}{c}{svm}\n",
      "\\\\\n",
      " & bpic2015\\_3 & bpic2011\\_3 & bpic2011\\_2 & sepsis\\_2 & bpic2015\\_1 & bpic2015\\_5\n",
      "\\\\ \\midrule\n",
      "cluster\\_laststate & $0.49$ ${(0.0)}$ & $0.91$ ${(0.59)}$ & $0.52$ ${(0.2)}$ & $0.5$ ${(0.0)}$ & $0.63$ ${(0.0)}$ & $0.5$ ${(0.0)}$ \\\\\n",
      "cluster\\_agg & $0.52$ ${(0.0)}$ & $0.52$ ${(0.0)}$ & $0.56$ ${(0.11)}$ & $0.5$ ${(0.0)}$ & $0.56$ ${(0.0)}$ & $0.5$ ${(0.0)}$ \\\\\n",
      "single\\_agg & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.77)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.57$ ${(0.0)}$ \\\\\n",
      "prefix\\_agg & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ \\\\\n",
      "prefix\\_laststate & $0.56$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.77)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ \\\\\n",
      "single\\_laststate & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.77)}$ & $0.5$ ${(0.0)}$ & $0.48$ ${(0.0)}$ & $0.57$ ${(0.19)}$ \\\\\n",
      "prefix\\_index & $0.53$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.8)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ \\\\\n",
      "state\\_agg & $0.56$ ${(0.15)}$ & $0.72$ ${(0.05)}$ & $0.51$ ${(0.71)}$ & $0.33$ ${(0.0)}$ & $0.62$ ${(0.32)}$ & $0.57$ ${(0.0)}$ \\\\\n",
      "state\\_laststate & $0.49$ ${(0.0)}$ & $0.58$ ${(0.0)}$ & $0.55$ ${(0.63)}$ & $0.33$ ${(0.0)}$ & $0.62$ ${(0.34)}$ & $0.5$ ${(0.0)}$ \\\\\n",
      "\\bottomrule\n",
      "\\toprule\n",
      " & \\multicolumn{5}{c}{svm}\n",
      "\\\\\n",
      " & sepsis\\_1 & bpic2017\\_c & sepsis\\_3 & bpic2012\\_c & production & bpic2011\\_1\n",
      "\\\\ \\midrule\n",
      "cluster\\_laststate & $0.44$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.52$ ${(0.0)}$ & $0.59$ ${(0.0)}$ & $0.58$ ${(0.53)}$ & $0.53$ ${(0.54)}$ \\\\\n",
      "cluster\\_agg & $0.51$ ${(0.0)}$ & $-$  & $0.97$ ${(0.34)}$ & $0.48$ ${(0.0)}$ & $0.61$ ${(0.52)}$ & $0.68$ ${(0.54)}$ \\\\\n",
      "single\\_agg & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.52$ ${(0.0)}$ & $0.54$ ${(0.0)}$ & $0.5$ ${(0.53)}$ & $0.5$ ${(0.0)}$ \\\\\n",
      "prefix\\_agg & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.63$ ${(0.0)}$ & $0.52$ ${(0.0)}$ & $0.5$ ${(0.0)}$ \\\\\n",
      "prefix\\_laststate & $0.48$ ${(0.0)}$ & $0.81$ ${(0.06)}$ & $0.99$ ${(0.4)}$ & $0.5$ ${(0.0)}$ & $0.5$ ${(0.53)}$ & $0.5$ ${(0.0)}$ \\\\\n",
      "single\\_laststate & $0.45$ ${(0.0)}$ & $0.92$ ${(0.34)}$ & $0.84$ ${(0.0)}$ & $0.56$ ${(0.0)}$ & $0.52$ ${(0.06)}$ & $0.5$ ${(0.0)}$ \\\\\n",
      "prefix\\_index & $\\mathbf{0.61}$ $\\mathbf{(0.0)}$  & $0.97$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.79$ ${(0.0)}$ & $0.5$ ${(0.0)}$ & $0.91$ ${(0.0)}$ \\\\\n",
      "state\\_agg & $0.5$ ${(0.0)}$ & $-$  & $0.99$ ${(0.0)}$ & $0.66$ ${(0.08)}$ & $0.63$ ${(0.42)}$ & $0.65$ ${(0.66)}$ \\\\\n",
      "state\\_laststate & $0.48$ ${(0.0)}$ & $-$  & $0.52$ ${(0.0)}$ & $0.69$ ${(0.13)}$ & $0.59$ ${(0.54)}$ & $0.62$ ${(0.05)}$ \\\\\n",
      "\\bottomrule\n",
      "\\toprule\n",
      " & \\multicolumn{5}{c}{svm}\n",
      "\\\\\n",
      " & bpic2017\\_a\n",
      "\\\\ \\midrule\n",
      "cluster\\_laststate & $0.52$ ${(0.0)}$ \\\\\n",
      "cluster\\_agg & $-$  \\\\\n",
      "single\\_agg & $-$  \\\\\n",
      "prefix\\_agg & $0.5$ ${(0.0)}$ \\\\\n",
      "prefix\\_laststate & $-$  \\\\\n",
      "single\\_laststate & $-$  \\\\\n",
      "prefix\\_index & $0.5$ ${(0.0)}$ \\\\\n",
      "state\\_agg & $0.57$ ${(0.11)}$ \\\\\n",
      "state\\_laststate & $0.6$ ${(0.04)}$ \\\\\n",
      "\\bottomrule\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i=0\n",
    "for k in range(4):    \n",
    "    datasets = list(set(data['dataset']))[i:i+6]\n",
    "    #print(datasets)\n",
    "    i+=6\n",
    "    \n",
    "    # change this line for each classifiere\n",
    "    cls_methods=['svm']\n",
    "    #datasets = list(set(data['dataset']))[0:6]\n",
    "    print(\"\\\\toprule\")\n",
    "    print(\" & \".join([\"\"] + [\"\\\\multicolumn{5}{c}{%s}\" % cls for cls in cls_methods]))\n",
    "    print(\"\\\\\\\\\")\n",
    "    print(\" & \".join([\"\"] + [\"%s\"%dataset.replace(\"_\", \"\\\\_\") for dataset in datasets] * len(cls_methods)))\n",
    "    print(\"\\\\\\\\ \\\\midrule\")\n",
    "    for method in methods:\n",
    "        elems_to_print = [method.replace(\"_\", \"\\\\_\")]\n",
    "        if method not in tmp2_auc.groups:\n",
    "            continue\n",
    "        tmp_method_auc = tmp2_auc.get_group(method)\n",
    "        \n",
    "        if method not in tmp2_fsc.groups:\n",
    "            continue\n",
    "        tmp_method_fsc = tmp2_fsc.get_group(method)\n",
    "\n",
    "        tmp_method_cls_auc = tmp_method_auc.groupby(\"cls\")\n",
    "        tmp_method_cls_fsc = tmp_method_fsc.groupby(\"cls\")\n",
    "        for cls in cls_methods:\n",
    "            #print(cls)\n",
    "            tmp_cls_auc = tmp_method_cls_auc.get_group(cls)            \n",
    "            tmp_method_grouped_auc = tmp_cls_auc.groupby(\"dataset\")\n",
    "            \n",
    "            tmp_cls_fsc = tmp_method_cls_fsc.get_group(cls)            \n",
    "            tmp_method_grouped_fsc = tmp_cls_fsc.groupby(\"dataset\")\n",
    "            \n",
    "            \n",
    "            #print(tmp_method_grouped.head())\n",
    "            for dataset_name in datasets:  \n",
    "                #print(dataset_name)\n",
    "                if dataset_name not in tmp_method_grouped_auc.groups:\n",
    "                    elems_to_print.append(\"$-$ \")\n",
    "                    continue\n",
    "                tmp_dataset_auc = tmp_method_grouped_auc.get_group(dataset_name)\n",
    "                tmp_dataset_fsc = tmp_method_grouped_fsc.get_group(dataset_name)\n",
    "\n",
    "\n",
    "                mean_value_auc = np.average(tmp_dataset_auc[\"score\"], weights=tmp_dataset_auc[\"n_cases\"])\n",
    "                #print(mean_value)\n",
    "                variance_auc = np.average((tmp_dataset_auc[\"score\"]-mean_value_auc)**2, weights=tmp_dataset_auc[\"n_cases\"])\n",
    "                std_value_auc = round(np.sqrt(variance_auc), round_prec)\n",
    "                mean_value_auc = round(mean_value_auc, round_prec)\n",
    "                \n",
    "                mean_value_fsc = np.average(tmp_dataset_fsc[\"score\"], weights=tmp_dataset_fsc[\"n_cases\"])\n",
    "                #print(mean_value)\n",
    "                variance_fsc = np.average((tmp_dataset_fsc[\"score\"]-mean_value_fsc)**2, weights=tmp_dataset_fsc[\"n_cases\"])\n",
    "                std_value_fsc = round(np.sqrt(variance_fsc), round_prec)\n",
    "                mean_value_fsc = round(mean_value_fsc, round_prec)\n",
    "\n",
    "                current_str = \"\"\n",
    "                if mean_value_auc == best_mean_aucs[dataset_name]:\n",
    "                    current_str = \"$\\\\mathbf{%s}$ $\\\\mathbf{(%s)}$ \"%(mean_value_auc, mean_value_fsc)\n",
    "                else:\n",
    "                    current_str = \"$%s$ ${(%s)}$\" % (mean_value_auc, mean_value_fsc)\n",
    "\n",
    "                elems_to_print.append(current_str)\n",
    "\n",
    "        print(\"%s \\\\\\\\\"%(\" & \".join(elems_to_print)))\n",
    "\n",
    "    print(\"\\\\bottomrule\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "cls: xgboost\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\\toprule\n",
      " & \\multicolumn{2}{c}{{\\bfseries bpic2015\\_2}} & \\multicolumn{2}{c}{{\\bfseries bpic2012\\_C}} & \\multicolumn{2}{c}{{\\bfseries bpic2015\\_4}} \\\\ \\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n",
      "method  & training\\_total (s) & prediction\\_avg (ms) & training\\_total (s) & prediction\\_avg (ms) & training\\_total (s) & prediction\\_avg (ms) \\\\ \\midrule\n",
      "cluster\\_laststate & $4.88 \\pm 0.0$ & $0.01 \\pm 0.01$ & $60.94 \\pm 0.0$ & $0.01 \\pm 0.01$ & $3.64 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "cluster\\_agg & $5.41 \\pm 0.0$ & $0.01 \\pm 0.02$ & $75.17 \\pm 0.0$ & $0.01 \\pm 0.01$ & $4.77 \\pm 0.0$ & $0.01 \\pm 0.02$ \\\\ \n",
      "single\\_agg & $18.77 \\pm 0.0$ & $0.01 \\pm 0.01$ & $106.34 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.01}$ & $7.03 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "prefix\\_agg & $0.85 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $2.5 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $0.74 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "prefix\\_laststate & $0.86 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $2.55 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $0.63 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "single\\_laststate & $20.12 \\pm 0.0$ & $0.01 \\pm 0.01$ & $46.08 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.01}$ & $9.1 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "prefix\\_index & $\\mathbf{0.12 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ & $\\mathbf{0.72 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ & $\\mathbf{0.09 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "state\\_agg & $12.84 \\pm 0.0$ & $0.01 \\pm 0.02$ & $24.22 \\pm 0.0$ & $0.01 \\pm 0.01$ & $9.86 \\pm 0.0$ & $0.01 \\pm 0.02$ \\\\ \n",
      "state\\_laststate & $8.65 \\pm 0.0$ & $0.01 \\pm 0.02$ & $16.13 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.01}$ & $4.5 \\pm 0.0$ & $0.01 \\pm 0.02$ \\\\ \n",
      "\\bottomrule\n",
      "\\toprule\n",
      " & \\multicolumn{2}{c}{{\\bfseries bpic2012\\_D}} & \\multicolumn{2}{c}{{\\bfseries bpic2017\\_A}} & \\multicolumn{2}{c}{{\\bfseries bpic2011\\_4}} \\\\ \\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n",
      "method  & training\\_total (s) & prediction\\_avg (ms) & training\\_total (s) & prediction\\_avg (ms) & training\\_total (s) & prediction\\_avg (ms) \\\\ \\midrule\n",
      "cluster\\_laststate & $67.26 \\pm 0.0$ & $0.01 \\pm 0.01$ & $832.53 \\pm 0.0$ & $0.01 \\pm 0.01$ & $91.92 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "cluster\\_agg & $74.64 \\pm 0.0$ & $0.01 \\pm 0.01$ & $844.27 \\pm 0.0$ & $0.01 \\pm 0.01$ & $31.47 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "single\\_agg & $54.8 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.01}$ & $1468.06 \\pm 0.0$ & $0.01 \\pm 0.01$ & $26.69 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "prefix\\_agg & $2.6 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $6.78 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $1.15 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "prefix\\_laststate & $2.47 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $6.81 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $1.13 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "single\\_laststate & $162.49 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.01}$ & $1085.55 \\pm 0.0$ & $0.01 \\pm 0.01$ & $22.01 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "prefix\\_index & $\\mathbf{0.71 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ & $\\mathbf{5.25 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ & $\\mathbf{0.19 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "state\\_agg & $55.03 \\pm 0.0$ & $0.01 \\pm 0.01$ & $551.18 \\pm 0.0$ & $0.01 \\pm 0.01$ & $17.44 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "state\\_laststate & $35.62 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.01}$ & $270.3 \\pm 0.0$ & $0.01 \\pm 0.01$ & $26.1 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "\\bottomrule\n",
      "\\toprule\n",
      " & \\multicolumn{2}{c}{{\\bfseries bpic2012\\_A}} & \\multicolumn{2}{c}{{\\bfseries bpic2015\\_3}} & \\multicolumn{2}{c}{{\\bfseries bpic2011\\_3}} \\\\ \\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n",
      "method  & training\\_total (s) & prediction\\_avg (ms) & training\\_total (s) & prediction\\_avg (ms) & training\\_total (s) & prediction\\_avg (ms) \\\\ \\midrule\n",
      "cluster\\_laststate & $44.37 \\pm 0.0$ & $0.01 \\pm 0.01$ & $19.02 \\pm 0.0$ & $0.01 \\pm 0.02$ & $8.66 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "cluster\\_agg & $91.93 \\pm 0.0$ & $0.01 \\pm 0.01$ & $14.59 \\pm 0.0$ & $0.01 \\pm 0.02$ & $10.93 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "single\\_agg & $71.59 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.01}$ & $105.18 \\pm 0.0$ & $0.01 \\pm 0.01$ & $22.17 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "prefix\\_agg & $2.44 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $1.58 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $0.59 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "prefix\\_laststate & $2.45 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $1.37 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $0.58 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "single\\_laststate & $140.47 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.01}$ & $64.33 \\pm 0.0$ & $0.01 \\pm 0.01$ & $18.13 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "prefix\\_index & $\\mathbf{0.73 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ & $\\mathbf{0.21 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ & $\\mathbf{0.18 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "state\\_agg & $75.04 \\pm 0.0$ & $0.01 \\pm 0.01$ & $19.99 \\pm 0.0$ & $0.01 \\pm 0.02$ & $16.43 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "state\\_laststate & $34.25 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.01}$ & $10.85 \\pm 0.0$ & $0.01 \\pm 0.02$ & $9.51 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "\\bottomrule\n",
      "\\toprule\n",
      " & \\multicolumn{2}{c}{{\\bfseries sepsis\\_2}} & \\multicolumn{2}{c}{{\\bfseries bpic2011\\_2}} & \\multicolumn{2}{c}{{\\bfseries bpic2017\\_C}} \\\\ \\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n",
      "method  & training\\_total (s) & prediction\\_avg (ms) & training\\_total (s) & prediction\\_avg (ms) & training\\_total (s) & prediction\\_avg (ms) \\\\ \\midrule\n",
      "cluster\\_laststate & $1.62 \\pm 0.0$ & $0.02 \\pm 0.02$ & $27.91 \\pm 0.0$ & $0.02 \\pm 0.03$ & $216.15 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "cluster\\_agg & $2.38 \\pm 0.0$ & $0.02 \\pm 0.02$ & $17.26 \\pm 0.0$ & $0.02 \\pm 0.03$ & $446.0 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "single\\_agg & $1.72 \\pm 0.0$ & $0.02 \\pm 0.02$ & $31.26 \\pm 0.0$ & $0.02 \\pm 0.03$ & $914.57 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "prefix\\_agg & $0.16 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $1.23 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $6.78 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "prefix\\_laststate & $0.16 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $1.2 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $6.83 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "single\\_laststate & $1.52 \\pm 0.0$ & $0.02 \\pm 0.02$ & $42.13 \\pm 0.0$ & $0.02 \\pm 0.03$ & $779.63 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "prefix\\_index & $\\mathbf{0.14 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ & $\\mathbf{0.2 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ & $\\mathbf{5.4 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "state\\_agg & $2.34 \\pm 0.0$ & $0.02 \\pm 0.02$ & $18.86 \\pm 0.0$ & $0.02 \\pm 0.04$ & $289.58 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "state\\_laststate & $1.52 \\pm 0.0$ & $0.02 \\pm 0.02$ & $24.0 \\pm 0.0$ & $0.02 \\pm 0.03$ & $280.38 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "\\bottomrule\n",
      "\\toprule\n",
      " & \\multicolumn{2}{c}{{\\bfseries bpic2015\\_5}} & \\multicolumn{2}{c}{{\\bfseries sepsis\\_1}} & \\multicolumn{2}{c}{{\\bfseries sepsis\\_3}} \\\\ \\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n",
      "method  & training\\_total (s) & prediction\\_avg (ms) & training\\_total (s) & prediction\\_avg (ms) & training\\_total (s) & prediction\\_avg (ms) \\\\ \\midrule\n",
      "cluster\\_laststate & $28.22 \\pm 0.0$ & $0.01 \\pm 0.02$ & $3.58 \\pm 0.0$ & $0.01 \\pm 0.02$ & $2.11 \\pm 0.0$ & $0.02 \\pm 0.02$ \\\\ \n",
      "cluster\\_agg & $11.2 \\pm 0.0$ & $0.01 \\pm 0.02$ & $3.1 \\pm 0.0$ & $0.02 \\pm 0.02$ & $2.62 \\pm 0.0$ & $0.02 \\pm 0.02$ \\\\ \n",
      "single\\_agg & $29.88 \\pm 0.0$ & $0.01 \\pm 0.02$ & $3.08 \\pm 0.0$ & $0.01 \\pm 0.02$ & $2.72 \\pm 0.0$ & $0.01 \\pm 0.02$ \\\\ \n",
      "prefix\\_agg & $1.3 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $0.47 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $0.51 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "prefix\\_laststate & $1.14 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $0.47 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $0.51 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "single\\_laststate & $30.39 \\pm 0.0$ & $0.01 \\pm 0.01$ & $4.99 \\pm 0.0$ & $0.01 \\pm 0.01$ & $2.69 \\pm 0.0$ & $0.01 \\pm 0.02$ \\\\ \n",
      "prefix\\_index & $\\mathbf{0.17 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ & $\\mathbf{0.13 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ & $\\mathbf{0.13 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "state\\_agg & $11.47 \\pm 0.0$ & $0.01 \\pm 0.02$ & $4.58 \\pm 0.0$ & $0.02 \\pm 0.02$ & $3.93 \\pm 0.0$ & $0.02 \\pm 0.02$ \\\\ \n",
      "state\\_laststate & $8.13 \\pm 0.0$ & $0.01 \\pm 0.02$ & $2.73 \\pm 0.0$ & $0.01 \\pm 0.02$ & $2.29 \\pm 0.0$ & $0.01 \\pm 0.02$ \\\\ \n",
      "\\bottomrule\n",
      "\\toprule\n",
      " & \\multicolumn{2}{c}{{\\bfseries bpic2015\\_1}} & \\multicolumn{2}{c}{{\\bfseries production}} & \\multicolumn{2}{c}{{\\bfseries bpic2011\\_1}} \\\\ \\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n",
      "method  & training\\_total (s) & prediction\\_avg (ms) & training\\_total (s) & prediction\\_avg (ms) & training\\_total (s) & prediction\\_avg (ms) \\\\ \\midrule\n",
      "cluster\\_laststate & $4.71 \\pm 0.0$ & $0.01 \\pm 0.02$ & $0.67 \\pm 0.0$ & $0.01 \\pm 0.01$ & $16.29 \\pm 0.0$ & $0.02 \\pm 0.04$ \\\\ \n",
      "cluster\\_agg & $13.85 \\pm 0.0$ & $0.01 \\pm 0.02$ & $0.55 \\pm 0.0$ & $0.02 \\pm 0.01$ & $10.94 \\pm 0.0$ & $0.02 \\pm 0.04$ \\\\ \n",
      "single\\_agg & $14.5 \\pm 0.0$ & $0.01 \\pm 0.02$ & $0.55 \\pm 0.0$ & $0.01 \\pm 0.01$ & $17.88 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "prefix\\_agg & $0.76 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $0.12 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $0.82 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix\\_laststate & $0.76 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $0.12 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ & $0.81 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "single\\_laststate & $6.36 \\pm 0.0$ & $0.01 \\pm 0.01$ & $0.38 \\pm 0.0$ & $0.01 \\pm 0.01$ & $20.77 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "prefix\\_index & $\\mathbf{0.11 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ & $\\mathbf{0.04 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ & $\\mathbf{0.18 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "state\\_agg & $11.19 \\pm 0.0$ & $0.01 \\pm 0.02$ & $0.72 \\pm 0.0$ & $0.01 \\pm 0.01$ & $15.51 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "state\\_laststate & $8.72 \\pm 0.0$ & $0.01 \\pm 0.02$ & $0.54 \\pm 0.0$ & $0.01 \\pm 0.01$ & $17.31 \\pm 0.0$ & $0.02 \\pm 0.03$ \\\\ \n",
      "\\bottomrule\n",
      "\\toprule\n",
      " & \\multicolumn{2}{c}{{\\bfseries bpic2017\\_R}} \\\\ \\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n",
      "method  & training\\_total (s) & prediction\\_avg (ms) \\\\ \\midrule\n",
      "cluster\\_laststate & $377.35 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "cluster\\_agg & $986.18 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "single\\_agg & $930.87 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "prefix\\_agg & $7.54 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "prefix\\_laststate & $6.83 \\pm 0.0$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "single\\_laststate & $1245.79 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "prefix\\_index & $\\mathbf{5.33 \\pm 0.0}$ & $\\mathbf{0.0 \\pm 0.0}$ \\\\ \n",
      "state\\_agg & $514.08 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "state\\_laststate & $363.26 \\pm 0.0$ & $0.01 \\pm 0.01$ \\\\ \n",
      "\\bottomrule\n"
     ]
    }
   ],
   "source": [
    "data_cat=pd.read_csv('./../../results_all/catboost/code/final_data/time/Inter_data_time_catboost.csv', sep = ';')\n",
    "data = data_cat\n",
    "clfs = ['xgboost']\n",
    "for cls in clfs:\n",
    "    print(f\"\\n\\n\\n\\ncls: {cls}\\n\\n\\n\\n\")\n",
    "    cls = cls\n",
    "    data_cls = data[data.cls==cls]\n",
    "    best_offline_times = data_cls[data_cls.metric==\"offline_total_avg\"].groupby([\"dataset\"])[\"score\"].min().round(2)\n",
    "    best_online_times = data_cls[data_cls.metric==\"online_event_avg\"].groupby([\"dataset\"])[\"score\"].min().round(2)\n",
    "    \n",
    "    bucket_encs = list(set(data.bucket_enc))\n",
    "    methods = [\"%s\" % (bucket_enc) for bucket_enc in bucket_encs]\n",
    "    cls_methods = cls\n",
    " \n",
    "    # 6 by 6 for tables\n",
    "    i = 0\n",
    "    for k in range(7):\n",
    "        datasets =list(set(data['dataset']))[i:i+3]\n",
    "        i+=3\n",
    "\n",
    "        \n",
    "        print(\"\\\\toprule\")\n",
    "        print(\"%s \\\\\\\\ \\\\cmidrule(lr){2-3} \\\\cmidrule(lr){4-5} \\\\cmidrule(lr){6-7}\"%(\"\".join([\" & \\multicolumn{2}{c}{{\\\\bfseries %s}}\"%(dataset.replace(\"_\", \"\\\\_\")) for dataset in datasets])))\n",
    "        print(\"method \" + \" & training\\\\_total (s) & prediction\\\\_avg (ms)\" * len(datasets) + \" \\\\\\\\ \\midrule\")\n",
    "\n",
    "        for bucket_enc in bucket_encs:\n",
    "        \n",
    "            elems_to_print = [bucket_enc.replace(\"_\", \"\\\\_\")]\n",
    "            for dataset in datasets:\n",
    "\n",
    "                dt_sub = data_cls[(data_cls.dataset==dataset) & (data_cls.bucket_enc==bucket_enc) ]\n",
    "                if len(dt_sub) > 0:\n",
    "                    offline_mean = round(dt_sub[dt_sub.metric==\"offline_total_avg\"].score.iloc[0], 2)\n",
    "                    offline_std = round(dt_sub[dt_sub.metric==\"offline_total_std\"].score.iloc[0], 2)\n",
    "                    online_mean = round(dt_sub[dt_sub.metric==\"online_event_avg\"].score.iloc[0], 2)\n",
    "                    online_std = round(dt_sub[dt_sub.metric==\"online_event_std\"].score.iloc[0], 2)\n",
    "\n",
    "                    if offline_mean == best_offline_times[dataset]:\n",
    "                        elems_to_print.append(\"$\\\\mathbf{%s \\\\pm %s}$\" % (offline_mean, offline_std))\n",
    "                    else:\n",
    "                        elems_to_print.append(\"$%s \\\\pm %s$\" % (offline_mean, offline_std))\n",
    "\n",
    "                    if online_mean == best_online_times[dataset]:\n",
    "                        elems_to_print.append(\"$\\\\mathbf{%s \\\\pm %s}$\" % (online_mean, online_std))\n",
    "                    else:\n",
    "                        elems_to_print.append(\"$%s \\\\pm %s$\" % (online_mean, online_std))\n",
    "\n",
    "                else:\n",
    "                    elems_to_print.extend([\"-\", \"-\"])\n",
    "\n",
    "            print(\"%s \\\\\\\\ \"%(\" & \".join(elems_to_print)))\n",
    "        print(\"\\\\bottomrule\")\n",
    "\n",
    "    #break\n",
    "    #datasets = list(set(data['dataset']))[0:3]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
